{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data,device):\n",
    "    if isinstance(data, (list,tuple)): #The isinstance() function returns True if the specified object is of the specified type, otherwise False.\n",
    "        return [to_device(x,device) for x in data]\n",
    "    return data.to(device,non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    def __init__(self,dl,device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b,self.device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:1374: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000]\tLoss: 2.305815\n",
      "Train Epoch: 0 [6400/60000]\tLoss: 0.190469\n",
      "Train Epoch: 0 [12800/60000]\tLoss: 0.269778\n",
      "Train Epoch: 0 [19200/60000]\tLoss: 0.107482\n",
      "Train Epoch: 0 [25600/60000]\tLoss: 0.081234\n",
      "Train Epoch: 0 [32000/60000]\tLoss: 0.139888\n",
      "Train Epoch: 0 [38400/60000]\tLoss: 0.278301\n",
      "Train Epoch: 0 [44800/60000]\tLoss: 0.229512\n",
      "Train Epoch: 0 [51200/60000]\tLoss: 0.103200\n",
      "Train Epoch: 0 [57600/60000]\tLoss: 0.153382\n",
      "Train Epoch: 1 [0/60000]\tLoss: 0.110708\n",
      "Train Epoch: 1 [6400/60000]\tLoss: 0.148999\n",
      "Train Epoch: 1 [12800/60000]\tLoss: 0.079755\n",
      "Train Epoch: 1 [19200/60000]\tLoss: 0.184182\n",
      "Train Epoch: 1 [25600/60000]\tLoss: 0.050171\n",
      "Train Epoch: 1 [32000/60000]\tLoss: 0.077771\n",
      "Train Epoch: 1 [38400/60000]\tLoss: 0.010460\n",
      "Train Epoch: 1 [44800/60000]\tLoss: 0.107510\n",
      "Train Epoch: 1 [51200/60000]\tLoss: 0.021701\n",
      "Train Epoch: 1 [57600/60000]\tLoss: 0.083223\n",
      "Train Epoch: 2 [0/60000]\tLoss: 0.097227\n",
      "Train Epoch: 2 [6400/60000]\tLoss: 0.022836\n",
      "Train Epoch: 2 [12800/60000]\tLoss: 0.078335\n",
      "Train Epoch: 2 [19200/60000]\tLoss: 0.138316\n",
      "Train Epoch: 2 [25600/60000]\tLoss: 0.072602\n",
      "Train Epoch: 2 [32000/60000]\tLoss: 0.007325\n",
      "Train Epoch: 2 [38400/60000]\tLoss: 0.070242\n",
      "Train Epoch: 2 [44800/60000]\tLoss: 0.007205\n",
      "Train Epoch: 2 [51200/60000]\tLoss: 0.065398\n",
      "Train Epoch: 2 [57600/60000]\tLoss: 0.066215\n",
      "Train Epoch: 3 [0/60000]\tLoss: 0.011553\n",
      "Train Epoch: 3 [6400/60000]\tLoss: 0.054607\n",
      "Train Epoch: 3 [12800/60000]\tLoss: 0.025621\n",
      "Train Epoch: 3 [19200/60000]\tLoss: 0.011846\n",
      "Train Epoch: 3 [25600/60000]\tLoss: 0.046390\n",
      "Train Epoch: 3 [32000/60000]\tLoss: 0.159338\n",
      "Train Epoch: 3 [38400/60000]\tLoss: 0.056447\n",
      "Train Epoch: 3 [44800/60000]\tLoss: 0.026626\n",
      "Train Epoch: 3 [51200/60000]\tLoss: 0.020589\n",
      "Train Epoch: 3 [57600/60000]\tLoss: 0.015630\n",
      "Train Epoch: 4 [0/60000]\tLoss: 0.003207\n",
      "Train Epoch: 4 [6400/60000]\tLoss: 0.006765\n",
      "Train Epoch: 4 [12800/60000]\tLoss: 0.032639\n",
      "Train Epoch: 4 [19200/60000]\tLoss: 0.034429\n",
      "Train Epoch: 4 [25600/60000]\tLoss: 0.046565\n",
      "Train Epoch: 4 [32000/60000]\tLoss: 0.013033\n",
      "Train Epoch: 4 [38400/60000]\tLoss: 0.028688\n",
      "Train Epoch: 4 [44800/60000]\tLoss: 0.026264\n",
      "Train Epoch: 4 [51200/60000]\tLoss: 0.053118\n",
      "Train Epoch: 4 [57600/60000]\tLoss: 0.034004\n",
      "Train Epoch: 5 [0/60000]\tLoss: 0.026938\n",
      "Train Epoch: 5 [6400/60000]\tLoss: 0.012821\n",
      "Train Epoch: 5 [12800/60000]\tLoss: 0.021371\n",
      "Train Epoch: 5 [19200/60000]\tLoss: 0.111125\n",
      "Train Epoch: 5 [25600/60000]\tLoss: 0.056198\n",
      "Train Epoch: 5 [32000/60000]\tLoss: 0.023835\n",
      "Train Epoch: 5 [38400/60000]\tLoss: 0.003913\n",
      "Train Epoch: 5 [44800/60000]\tLoss: 0.153686\n",
      "Train Epoch: 5 [51200/60000]\tLoss: 0.193281\n",
      "Train Epoch: 5 [57600/60000]\tLoss: 0.017196\n",
      "Train Epoch: 6 [0/60000]\tLoss: 0.015063\n",
      "Train Epoch: 6 [6400/60000]\tLoss: 0.059429\n",
      "Train Epoch: 6 [12800/60000]\tLoss: 0.009885\n",
      "Train Epoch: 6 [19200/60000]\tLoss: 0.054515\n",
      "Train Epoch: 6 [25600/60000]\tLoss: 0.049402\n",
      "Train Epoch: 6 [32000/60000]\tLoss: 0.054716\n",
      "Train Epoch: 6 [38400/60000]\tLoss: 0.005039\n",
      "Train Epoch: 6 [44800/60000]\tLoss: 0.004972\n",
      "Train Epoch: 6 [51200/60000]\tLoss: 0.016636\n",
      "Train Epoch: 6 [57600/60000]\tLoss: 0.012324\n",
      "Train Epoch: 7 [0/60000]\tLoss: 0.049095\n",
      "Train Epoch: 7 [6400/60000]\tLoss: 0.010658\n",
      "Train Epoch: 7 [12800/60000]\tLoss: 0.083711\n",
      "Train Epoch: 7 [19200/60000]\tLoss: 0.006811\n",
      "Train Epoch: 7 [25600/60000]\tLoss: 0.001719\n",
      "Train Epoch: 7 [32000/60000]\tLoss: 0.018340\n",
      "Train Epoch: 7 [38400/60000]\tLoss: 0.079755\n",
      "Train Epoch: 7 [44800/60000]\tLoss: 0.040802\n",
      "Train Epoch: 7 [51200/60000]\tLoss: 0.004337\n",
      "Train Epoch: 7 [57600/60000]\tLoss: 0.005417\n",
      "Train Epoch: 8 [0/60000]\tLoss: 0.001953\n",
      "Train Epoch: 8 [6400/60000]\tLoss: 0.021534\n",
      "Train Epoch: 8 [12800/60000]\tLoss: 0.035860\n",
      "Train Epoch: 8 [19200/60000]\tLoss: 0.027478\n",
      "Train Epoch: 8 [25600/60000]\tLoss: 0.053677\n",
      "Train Epoch: 8 [32000/60000]\tLoss: 0.016146\n",
      "Train Epoch: 8 [38400/60000]\tLoss: 0.006839\n",
      "Train Epoch: 8 [44800/60000]\tLoss: 0.087713\n",
      "Train Epoch: 8 [51200/60000]\tLoss: 0.059402\n",
      "Train Epoch: 8 [57600/60000]\tLoss: 0.010511\n",
      "Train Epoch: 9 [0/60000]\tLoss: 0.002366\n",
      "Train Epoch: 9 [6400/60000]\tLoss: 0.009771\n",
      "Train Epoch: 9 [12800/60000]\tLoss: 0.000525\n",
      "Train Epoch: 9 [19200/60000]\tLoss: 0.006053\n",
      "Train Epoch: 9 [25600/60000]\tLoss: 0.001186\n",
      "Train Epoch: 9 [32000/60000]\tLoss: 0.008189\n",
      "Train Epoch: 9 [38400/60000]\tLoss: 0.000871\n",
      "Train Epoch: 9 [44800/60000]\tLoss: 0.122742\n",
      "Train Epoch: 9 [51200/60000]\tLoss: 0.010426\n",
      "Train Epoch: 9 [57600/60000]\tLoss: 0.009828\n",
      "Train Epoch: 10 [0/60000]\tLoss: 0.001507\n",
      "Train Epoch: 10 [6400/60000]\tLoss: 0.043958\n",
      "Train Epoch: 10 [12800/60000]\tLoss: 0.087803\n",
      "Train Epoch: 10 [19200/60000]\tLoss: 0.011484\n",
      "Train Epoch: 10 [25600/60000]\tLoss: 0.076798\n",
      "Train Epoch: 10 [32000/60000]\tLoss: 0.006273\n",
      "Train Epoch: 10 [38400/60000]\tLoss: 0.001345\n",
      "Train Epoch: 10 [44800/60000]\tLoss: 0.029538\n",
      "Train Epoch: 10 [51200/60000]\tLoss: 0.000312\n",
      "Train Epoch: 10 [57600/60000]\tLoss: 0.009319\n",
      "Train Epoch: 11 [0/60000]\tLoss: 0.015088\n",
      "Train Epoch: 11 [6400/60000]\tLoss: 0.011843\n",
      "Train Epoch: 11 [12800/60000]\tLoss: 0.000573\n",
      "Train Epoch: 11 [19200/60000]\tLoss: 0.093619\n",
      "Train Epoch: 11 [25600/60000]\tLoss: 0.005339\n",
      "Train Epoch: 11 [32000/60000]\tLoss: 0.025759\n",
      "Train Epoch: 11 [38400/60000]\tLoss: 0.002836\n",
      "Train Epoch: 11 [44800/60000]\tLoss: 0.046659\n",
      "Train Epoch: 11 [51200/60000]\tLoss: 0.105996\n",
      "Train Epoch: 11 [57600/60000]\tLoss: 0.051421\n",
      "Train Epoch: 12 [0/60000]\tLoss: 0.111497\n",
      "Train Epoch: 12 [6400/60000]\tLoss: 0.005317\n",
      "Train Epoch: 12 [12800/60000]\tLoss: 0.017018\n",
      "Train Epoch: 12 [19200/60000]\tLoss: 0.047374\n",
      "Train Epoch: 12 [25600/60000]\tLoss: 0.014799\n",
      "Train Epoch: 12 [32000/60000]\tLoss: 0.008846\n",
      "Train Epoch: 12 [38400/60000]\tLoss: 0.000325\n",
      "Train Epoch: 12 [44800/60000]\tLoss: 0.000871\n",
      "Train Epoch: 12 [51200/60000]\tLoss: 0.074374\n",
      "Train Epoch: 12 [57600/60000]\tLoss: 0.006307\n",
      "Train Epoch: 13 [0/60000]\tLoss: 0.010818\n",
      "Train Epoch: 13 [6400/60000]\tLoss: 0.004251\n",
      "Train Epoch: 13 [12800/60000]\tLoss: 0.002504\n",
      "Train Epoch: 13 [19200/60000]\tLoss: 0.005668\n",
      "Train Epoch: 13 [25600/60000]\tLoss: 0.045848\n",
      "Train Epoch: 13 [32000/60000]\tLoss: 0.006460\n",
      "Train Epoch: 13 [38400/60000]\tLoss: 0.007249\n",
      "Train Epoch: 13 [44800/60000]\tLoss: 0.003724\n",
      "Train Epoch: 13 [51200/60000]\tLoss: 0.028109\n",
      "Train Epoch: 13 [57600/60000]\tLoss: 0.063024\n",
      "Train Epoch: 14 [0/60000]\tLoss: 0.002206\n",
      "Train Epoch: 14 [6400/60000]\tLoss: 0.006683\n",
      "Train Epoch: 14 [12800/60000]\tLoss: 0.005101\n",
      "Train Epoch: 14 [19200/60000]\tLoss: 0.000546\n",
      "Train Epoch: 14 [25600/60000]\tLoss: 0.008290\n",
      "Train Epoch: 14 [32000/60000]\tLoss: 0.016102\n",
      "Train Epoch: 14 [38400/60000]\tLoss: 0.012544\n",
      "Train Epoch: 14 [44800/60000]\tLoss: 0.005858\n",
      "Train Epoch: 14 [51200/60000]\tLoss: 0.081859\n",
      "Train Epoch: 14 [57600/60000]\tLoss: 0.015873\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = nn.functional.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "train_loader = DeviceDataLoader(train_loader, device)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=True)\n",
    "test_loader = DeviceDataLoader(test_loader, device)\n",
    "    \n",
    "# Initialize the model\n",
    "model = Net().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(15):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{}]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dl.dataset), loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3200238863937557\n",
      "Test accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        test_loss += loss_function(output, target).item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', correct / len(test_loader.dl.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'mnist_cnn.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
